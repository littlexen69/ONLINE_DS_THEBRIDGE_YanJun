# Stock Prediction ‚Äî XGBoost + Streamlit

Aplicaci√≥n sencilla para **predecir el precio de cierre ajustado del d√≠a siguiente** de varias acciones (Apple, Google, Inditex, Johnson & Johnson, JPMorgan y Tesla) usando *feature engineering* cl√°sico y un modelo **XGBoostRegressor**. Incluye scripts para **descargar y procesar datos**, **entrenar y evaluar** el modelo, y una interfaz **Streamlit** para visualizar una predicci√≥n r√°pida.

> ‚ö†Ô∏è **Aviso**: Este proyecto es solo educativo. **No es asesoramiento financiero**. La predicci√≥n a un d√≠a con datos t√©cnicos puede ser ruidosa e inestable. √ösalo bajo tu responsabilidad.

---

## üß≠ √çndice

- [Arquitectura](#arquitectura)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n (API key)](#configuraci√≥n-api-key)
- [Obtenci√≥n y procesado de datos](#obtenci√≥n-y-procesado-de-datos)
- [Entrenamiento y evaluaci√≥n](#entrenamiento-y-evaluaci√≥n)
- [App Streamlit](#app-streamlit)
- [Estructura de carpetas](#estructura-de-carpetas)
- [Ingenier√≠a de caracter√≠sticas](#ingenier√≠a-de-caracter√≠sticas)
- [C√≥mo a√±adir nuevos *tickers*](#c√≥mo-a√±adir-nuevos-tickers)
- [Soluci√≥n de problemas](#soluci√≥n-de-problemas)
- [Licencia](#licencia)

---

## Arquitectura

- `data_processing.py`: descarga hist√≥ricos diarios de EODHD para varios *tickers*, crea caracter√≠sticas y genera conjuntos **raw** y **processed**.
- `training.py`: escala caracter√≠sticas/objetivo con **MinMaxScaler**, entrena un **XGBRegressor**, realiza **walk-forward validation** y guarda modelos.
- `evaluation.py`: calcula y muestra **RMSE** y curvas *Actual vs Predicted*; expone funciones/valores para la app.
- `main.py`: **Streamlit** con un selector de empresa y bot√≥n ‚ÄúPredecir ma√±ana‚Äù.

---

## Requisitos

- **Python 3.10+** (recomendado)
- Paquetes de `requirements.txt` (NumPy, Pandas, scikit-learn, XGBoost, Statsmodels, Streamlit, eodhd, etc.).

```bash
pip install -r requirements.txt
```

> Nota: XGBoost usa `tree_method="hist"` y CPU por defecto en este proyecto.

---

## Instalaci√≥n

1. Clona o copia este repo.
2. (Opcional) Crea y activa un entorno virtual.
3. Instala dependencias:
   ```bash
   pip install -r requirements.txt
   ```

---

## Configuraci√≥n (API key)

Los datos se descargan del servicio **EODHD**. Necesitas una **API key** v√°lida.

**Recomendado**: usa una variable de entorno en lugar de hardcodear la clave.

```python
# data_processing.py (ejemplo)
import os
from eodhd import APIClient

api = APIClient(api_key=os.getenv("EODHD_API_KEY"))
```

En tu terminal:
```bash
# macOS / Linux
export EODHD_API_KEY="TU_API_KEY"

# Windows PowerShell
$env:EODHD_API_KEY="TU_API_KEY"
```

---

## Obtenci√≥n y procesado de datos

Ejecuta:

```bash
python data_processing.py
```

Qu√© hace:
- Descarga hist√≥ricos diarios desde **2010-01-01** para: `AAPL.US, GOOGL.US, TSLA.US, JNJ.US, JPM.US, ITX.MC`.
- Guarda CSV en `data/raw/` (recomendado) y genera `data/processed/*.csv` con las features y la variable `target` (precio ajustado del d√≠a siguiente).

> üí° **Rutas**: En el c√≥digo original se usan rutas relativas del tipo `../data/...`. Si ejecutas los scripts desde la carpeta ra√≠z del proyecto, se recomienda cambiar a `./data/...` para evitar confusiones (ver secci√≥n *Soluci√≥n de problemas*).

---

## Entrenamiento y evaluaci√≥n

Entrena y valida con *walk-forward*:

```bash
python training.py
```

- Escala X e y con `MinMaxScaler`.
- Entrena `XGBRegressor(n_estimators=1000, tree_method="hist", device="cpu")`.
- Realiza **walk-forward validation** (predice paso a paso sobre el √∫ltimo 20% de datos).
- Calcula **RMSE de test** y guarda modelos en `models/*.json`.

Eval√∫a y visualiza:

```bash
python evaluation.py
```

- Imprime **RMSE de *train* y *test***.
- Muestra gr√°ficos *Actual vs Predicted* con `matplotlib`.
- Calcula una **predicci√≥n para el d√≠a siguiente** usando la √∫ltima fila disponible de cada *ticker*.

---

## App Streamlit

Ejecuta la app en alguna terminal de Windows (Powershell, cmd,...):

```bash
streamlit run main.py
```

La interfaz permite elegir entre **Apple, Google, Inditex, Johnson & Johnson, JPMorgan y Tesla** y obtener la **predicci√≥n del d√≠a siguiente**.

### Recursos de imagen
El script espera ficheros de logo/imagen en el mismo directorio que `main.py` con estos nombres:
```
aapl.png  googl.png  itx.png  jnj.png  jpm.png  tsla.png
```
Col√≥calos o elimina las llamadas `st.image(...)` si no los necesitas.

### Nota sobre *imports* en `main.py`
El archivo original usa un `sys.path.append(...)` con una **ruta absoluta de Windows** y `import sources.evaluation`. Para un entorno port√°til, sustituye por **imports relativos** si `evaluation.py` est√° en la misma carpeta:

```python
# main.py (recomendado)
import evaluation  # y usa evaluation.prediction_aapl, etc.
```

---

## Estructura de carpetas

Sugerencia de estructura (tras ejecutar los scripts):

```
project/
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ raw/
‚îÇ  ‚îÇ  ‚îú‚îÄ AAPL.US.csv
‚îÇ  ‚îÇ  ‚îú‚îÄ GOOGL.US.csv
‚îÇ  ‚îÇ  ‚îî‚îÄ ...
‚îÇ  ‚îî‚îÄ processed/
‚îÇ     ‚îú‚îÄ df_aapl.csv
‚îÇ     ‚îú‚îÄ df_googl.csv
‚îÇ     ‚îî‚îÄ ...
‚îú‚îÄ models/
‚îÇ  ‚îú‚îÄ aapl_model.json
‚îÇ  ‚îú‚îÄ googl_model.json
‚îÇ  ‚îî‚îÄ ...
‚îú‚îÄ main.py
‚îú‚îÄ data_processing.py
‚îú‚îÄ training.py
‚îú‚îÄ evaluation.py
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
```

> Los ficheros `*.pyc` son artefactos compilados y pueden ignorarse o eliminarse.

---

## Ingenier√≠a de caracter√≠sticas

Para cada *ticker* se generan, entre otras, las siguientes *features*:

- Diferencias: `close_diff_1`, `adjusted_close(-1)` (lag 1).
- Calendario: `dayofweek, quarter, month, year, dayofyear, dayofmonth, weekofyear`.
- Medias m√≥viles: `SMA(13)`, `EMA(9)`.
- Tendencia: `MACD` (EMA 24 ‚Äì EMA 52).
- Volatilidad bandas de Bollinger (10): diferencia `Upper_Band - Lower_Band`.
- Rango diario: `H_L_diff = high - low`.
- **Target**: `target = adjusted_close.shift(-1)` (valor del d√≠a siguiente).

> Nota: La implementaci√≥n del RSI usa una raz√≥n `ema_up/ema_down` como proxy. Si buscas el RSI cl√°sico (0‚Äì100), puedes convertirla con la f√≥rmula est√°ndar: `100 - (100 / (1 + RS))`.

---

## C√≥mo a√±adir nuevos *tickers*

1. A√±ade el s√≠mbolo a `TICKERS` en `data_processing.py` (formato EODHD, p. ej. `MSFT.US`).
2. Vuelve a ejecutar `python data_processing.py` para generar los CSV.
3. Aseg√∫rate de que `training.py` y `evaluation.py` cargan y tratan esos nuevos `df_*` (sigue el patr√≥n existente).
4. (Opcional) A√±ade el nombre y el logo en `main.py` para que aparezca en la app.

---

## Soluci√≥n de problemas

- **ImportError en `main.py` por ruta absoluta**  
  Cambia a imports relativos: `import evaluation` o reestructura los m√≥dulos en un paquete.

- **Rutas `../data/...`**  
  Si ejecutas desde la ra√≠z del proyecto, sustituye `../data/...` por `./data/...` en los scripts, o lanza los scripts desde la carpeta adecuada.

- **Faltan im√°genes**  
  La app llama a `st.image("aapl.png")`, etc. Coloca los ficheros o elimina esas l√≠neas.

- **Sin API key / 403**  
  Define `EODHD_API_KEY` en tus variables de entorno.

- **Predicciones inestables**  
  Ajusta *features*, tama√±o de ventana, `n_estimators`, o cambia a un *split* temporal m√°s robusto. Considera semilla aleatoria y *early stopping*.

---

## Licencia

Indica aqu√≠ la licencia del proyecto (por ejemplo, MIT).

